{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t5-pawraphrase.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "Python 3.7.9 64-bit",
      "display_name": "Python 3.7.9 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJWl3gIr1gKL"
      },
      "source": [
        "!pip3 install torch==1.7.0 -q\n",
        "!pip3 install transformers==2.9.0 -q\n",
        "!pip3 install pytorch_lightning==0.7.5 -q\n",
        "!pip3 install gdown -q\n",
        "!mkdir t5-p\n",
        "\n",
        "import gdown \n",
        "import os.path\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "\n",
        "# model_location = \"https://drive.google.com/LINK_TO_MODEL\"\n",
        "# config_location = \"https://drive.google.com/LINK_TO_MODEL\"\n",
        "# if os.path.isfile(datamodel):\n",
        "#     ('Model was already downloaded.')\n",
        "# else:\n",
        "#     gdown.download(model_location, datamodel, True)\n",
        "#     gdown.download(config_location, config_file, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6uyxYi-J8pz"
      },
      "source": [
        "datamodel = 't5-p/pytorch_model.bin'\n",
        "config_file = 't5-p/config.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JNmiqR6xtRJ"
      },
      "source": [
        "def set_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('./t5-p/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('custom_corpus/input.txt') as f:\n",
        "    mylist = f.read().splitlines()\n",
        "\n",
        "print('Number of sentences to be paraphrased: ', len(mylist))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GACBZklk1drQ",
        "outputId": "4622b8aa-129e-4e21-fec7-3c45284b6a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "inputs = []\n",
        "final_outputs = []\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "for sentence in mylist: \n",
        "    max_len = 256\n",
        "\n",
        "    encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
        "    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "    beam_outputs = model.generate(\n",
        "        input_ids=input_ids, \n",
        "        attention_mask=attention_masks,\n",
        "        do_sample=True,\n",
        "        max_length=256,\n",
        "        top_k=120,\n",
        "        top_p=0.98,\n",
        "        early_stopping=True,\n",
        "        num_return_sequences=1\n",
        "    )   \n",
        "\n",
        "    for beam_output in beam_outputs:\n",
        "        sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "        if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
        "            inputs.append(sentence)\n",
        "            final_outputs.append(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dict = {'Inputs': inputs, 'Paraphrase': final_outputs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir synthetic_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(dict)\n",
        "df.to_csv('synthetic_data/synthetic_paraphrases.csv')"
      ]
    }
  ]
}